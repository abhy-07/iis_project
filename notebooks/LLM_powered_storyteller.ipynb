{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (1.46.0)\n",
      "Requirement already satisfied: pillow in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (12.0.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (2.42.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (2.12.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/cvv/miniforge3/envs/ml312/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-genai pillow  # run once in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"<YOUR_KEY_HERE>\")\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "story_chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=(\n",
    "            \"You are Furhat, a friendly speaking robot and interactive storyteller. \"\n",
    "            \"You always speak directly to the user as 'you'. \"\n",
    "            \"Your answers must be medium short, 4-6 sentences, suitable for being spoken aloud.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "def generate_scene_text_llm(story, scene, emotion: str) -> str:\n",
    "    \"\"\"\n",
    "    Use LLM to generate narration for ONE scene.\n",
    "    Reads scene['llmHints'] and injects them into the prompt.\n",
    "    \"\"\"\n",
    "    hints = scene.get(\"llmHints\", {})\n",
    "    general_hint = hints.get(\"general\", \"\")\n",
    "    emotion_hint = hints.get(emotion, \"\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Story id: {story['id']}\n",
    "Story name: {story['name']}\n",
    "Genre: {story['genre']}\n",
    "\n",
    "\n",
    "Current scene id: {scene['id']}\n",
    "Scene type: {scene.get('type', 'normal')}\n",
    "Scene description: {scene['description']}\n",
    "\n",
    "\n",
    "Detected emotion label: {emotion}\n",
    "\n",
    "General scene hint: {general_hint}\n",
    "Emotion-specific hint: {emotion_hint}\n",
    "\n",
    "Write the narration for THIS scene only.\n",
    "\n",
    "Requirements:\n",
    "- 4 to 6 sentences.\n",
    "- Match the emotional tone to the detected emotion = {emotion}.\n",
    "- Do NOT mention the option texts or describe future choices explicitly.\n",
    "- Do NOT jump to future scenes.\n",
    "- Talk directly to the user as \"you\".\n",
    "\"\"\"\n",
    "    resp = story_chat.send_message(prompt)\n",
    "    return resp.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from furhat_remote_api import FurhatRemoteAPI\n",
    "furhat = FurhatRemoteAPI(\"localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Successfully changed Furhat voice', 'success': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "furhat.set_face(character='Titan', mask=\"Adult\")\n",
    "furhat.set_voice(name='Joanna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data/processed/LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LLM_as', 'LLM_lk', 'LLM_sa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_all_stories():\n",
    "    stories = {}\n",
    "    for path in DATA_PATH.glob(\"*.json\"):\n",
    "        story_id = path.stem\n",
    "        with open(path, \"r\") as f:\n",
    "            stories[story_id] = json.load(f)\n",
    "    return stories\n",
    "\n",
    "STORIES = load_all_stories()\n",
    "list(STORIES.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_emotions(stories):\n",
    "    emos = set()\n",
    "    for story in stories.values():\n",
    "        for scene in story[\"scenes\"]:\n",
    "            emos.update(scene.get(\"templates\", {}).keys())\n",
    "    return sorted(emos)\n",
    "\n",
    "EMOTIONS = get_all_emotions(STORIES)\n",
    "EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene(story, scene_id):\n",
    "    for scene in story[\"scenes\"]:\n",
    "        if scene[\"id\"] == scene_id:\n",
    "            return scene\n",
    "    return None\n",
    "\n",
    "def choose_template(scene, emotion):\n",
    "    \"\"\"Pick template for emotion, fall back to neutral or description.\"\"\"\n",
    "    return scene[\"templates\"].get(\n",
    "        emotion,\n",
    "        scene[\"templates\"].get(\"neutral\", scene[\"description\"])\n",
    "    )\n",
    "\n",
    "def next_scene(scene, chosen_option_id):\n",
    "    for opt in scene.get(\"options\", []):\n",
    "        if opt[\"id\"] == chosen_option_id:\n",
    "            return opt[\"nextScene\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggestion: remove all \"mood\" references and just use emotions everywhere, including in the JSON files\n",
    "KNOWN_MOODS = [\n",
    "    \"tired\", \"comfort-seeking\", \"sad\",\n",
    "    \"excited\", \"happy\", \"energized\",\n",
    "    \"neutral\", \"curious\"\n",
    "] # fix to match emotions?\n",
    "\n",
    "def detect_mood_from_text(text: str) -> str:\n",
    "    t = text.lower()\n",
    "    if \"comfort\" in t:\n",
    "        return \"comfort-seeking\"\n",
    "    for m in KNOWN_MOODS:\n",
    "        if m in t:\n",
    "            return m\n",
    "    # fallback\n",
    "    return \"neutral\"\n",
    "\n",
    "\n",
    "def detect_emotion_from_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Placeholder until the webcam model is integrated.\n",
    "    Maps some common words to your emotion labels.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    if any(w in t for w in [\"happy\", \"great\", \"good\", \"nice\"]):\n",
    "        return \"happy\"\n",
    "    if any(w in t for w in [\"sad\", \"down\", \"bad\"]):\n",
    "        return \"sad\"\n",
    "    if any(w in t for w in [\"angry\", \"mad\", \"annoyed\"]):\n",
    "        return \"angry\"\n",
    "    if any(w in t for w in [\"scared\", \"afraid\", \"fear\", \"nervous\"]):\n",
    "        return \"fear\"\n",
    "    if any(w in t for w in [\"disgust\", \"gross\"]):\n",
    "        return \"disgust\"\n",
    "    if any(w in t for w in [\"surprised\", \"wow\"]):\n",
    "        return \"surprised\"\n",
    "    return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_text(language: str = \"en-US\") -> str:\n",
    "    \"\"\"Listen once and return lowercase text, or '' if nothing.\"\"\"\n",
    "    response = furhat.listen(language=language)\n",
    "    if response and getattr(response, \"message\", None):\n",
    "        return response.message.strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_option_from_speech(scene, text: str):\n",
    "    \"\"\"\n",
    "    Try to map user's utterance to an option:\n",
    "    - number words (one, two, three...)\n",
    "    - digits (1, 2, 3)\n",
    "    - keywords from the option text\n",
    "    Returns option object or None.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "\n",
    "    options = scene.get(\"options\", [])\n",
    "    if not options:\n",
    "        return None\n",
    "\n",
    "    # digit index\n",
    "    for i, opt in enumerate(options, start=1):\n",
    "        if str(i) in t:\n",
    "            return opt\n",
    "\n",
    "    # word -> index\n",
    "    words_to_num = {\n",
    "        \"one\": 1, \"first\": 1,\n",
    "        \"two\": 2, \"second\": 2,\n",
    "        \"three\": 3, \"third\": 3\n",
    "    }\n",
    "    for w, num in words_to_num.items():\n",
    "        if w in t and 1 <= num <= len(options):\n",
    "            return options[num - 1]\n",
    "\n",
    "    # keyword match: if option text words appear\n",
    "    for opt in options:\n",
    "        key = opt[\"text\"].split()[0].lower()  # very simple\n",
    "        if key in t:\n",
    "            return opt\n",
    "\n",
    "    # fallback: first option\n",
    "    return options[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(text):\n",
    "     # Extract name from response (simple rule-based)\n",
    "    text = text.strip()\n",
    "    # Remove common phrases\n",
    "    words_to_remove = [\"my\", \"name\", \"is\", \"i'm\", \"im\", \"i\", \"am\", \"call\", \"me\"]\n",
    "    words = text.lower().split()\n",
    "    name_words = [w for w in words if w not in words_to_remove]\n",
    "        \n",
    "    if name_words:\n",
    "        return name_words[0].capitalize()\n",
    "    return \"Customer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_new_story(customer_name: str, current_story: str, stories=STORIES):\n",
    "    # List all story IDs except the one currently being told\n",
    "    available = [sid for sid in stories.keys() if sid != current_story]\n",
    "\n",
    "    # Create a natural-language list (e.g., \"dummy1, dummy3 or dummy5\")\n",
    "    if len(available) == 1:\n",
    "        options_text = available[0]\n",
    "    else:\n",
    "        options_text = \", \".join(available[:-1]) + f\" or {available[-1]}\"\n",
    "\n",
    "    # Ask user\n",
    "    furhat.say(\n",
    "        text=f\"I understand {customer_name}. Let's change to another story. \"\n",
    "             f\"Would you like {options_text}?\",\n",
    "        blocking=True\n",
    "    )\n",
    "\n",
    "    # Listen to their answer\n",
    "    answer = listen_text().lower()\n",
    "\n",
    "    # Rule-based matching against allowed stories only\n",
    "    for sid in available:\n",
    "        if sid.lower() in answer:\n",
    "            furhat.say(text=f\"Alright, switching to {sid}.\", blocking=True)\n",
    "            return sid\n",
    "\n",
    "    # If unclear — do not switch\n",
    "    furhat.say(text=\"I didn’t understand that. Let's continue with our current story.\", blocking=True)\n",
    "    return current_story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_story_session():\n",
    "    # --- Greeting & mood ---\n",
    "    furhat.say(text=\"Hello! I am your interactive storyteller.\", blocking=True)\n",
    "    furhat.say(text=\"What is your name?\", blocking = True)\n",
    "\n",
    "# Listen for name\n",
    "    response = furhat.listen()\n",
    "    if response and response.message:\n",
    "        customer_name = extract_name(response.message)\n",
    "        furhat.say(text=f\"Nice to meet you, {customer_name}!\", blocking = True)\n",
    "    else:\n",
    "        customer_name = \"Friend\"\n",
    "        furhat.say(text=\"Nice to meet you!\", blocking = True)\n",
    "    \n",
    "    # This should be done by the webcam\n",
    "    furhat.say(text=\"If I looked at your face, would you say you feel happy, sad, angry, afraid, disgusted, surprised, or neutral?\", blocking=True)\n",
    "    emotionresponse = furhat.listen()\n",
    "\n",
    "    if emotionresponse and emotionresponse.message:\n",
    "        user_emotion = detect_emotion_from_text(emotionresponse.message)\n",
    "        furhat.say(text=f\"You answered, {user_emotion}\", blocking = True)\n",
    "        if emotionresponse not in EMOTIONS:\n",
    "            emotion = \"neutral\"\n",
    "        else:\n",
    "            emotion=user_emotion\n",
    "        \n",
    "\n",
    "    #This should be done by webcam\n",
    "    furhat.say(text=\"How are you feeling right now?\", blocking=True)\n",
    "    mood_text = listen_text()\n",
    "    mood = detect_mood_from_text(mood_text)\n",
    "\n",
    "    # Ask which story the user would like\n",
    "    furhat.say(text=f\"{customer_name}, let's start a new story. Would you like LLM1, LLM2 or LLM3?\", blocking=True)\n",
    "    story_choice = listen_text()\n",
    "    # Rule-based problem detection\n",
    "    if any(word in story_choice for word in [\"LLM1\", \"first\", \"one\"]):\n",
    "        chosen_story = \"LLM_as\"\n",
    "        furhat.say(text=f\"Great choice, {customer_name}! Let's go for the LLM1 story!\", blocking = True)\n",
    "    elif any(word in story_choice for word in [\"LLM1\", \"second\", \"two\"]):\n",
    "        chosen_story = \"LLM_lk\"\n",
    "        furhat.say(text=f\"Great choice, {customer_name}! Let's go for the LLM2 story!\", blocking = True)\n",
    "    elif any(word in story_choice for word in [\"LLM3\", \"third\", \"tree\"]):\n",
    "        chosen_story = \"LLM_sa\"\n",
    "        furhat.say(text=f\"Great choice, {customer_name}! Let's go for the LLM3 story!\", blocking = True)\n",
    "    else:\n",
    "        furhat.say(text=\"I didn't catch that! Let's go for LLM1.\", blocking = True)\n",
    "        chosen_story = \"LLM_as\"\n",
    "        # chosen_story = select_story(mood, emotion)\n",
    "        # furhat.say(text=f\"Let's go for the {chosen_story} story!\", blocking=True)\n",
    "\n",
    "    \n",
    "\n",
    "    story = STORIES[chosen_story]\n",
    "    \n",
    "    furhat.say(text=f\"'{story['name']}' is a story about {story['shortDescription']}.\", blocking=True)\n",
    "\n",
    "\n",
    "    furhat.say(text=f\"Would you like to start the {story['name']}?\", blocking = True)\n",
    "    start_response = listen_text()\n",
    "    if any(word in start_response for word in [\"yes\", \"start\"]):\n",
    "        scene_id = story[\"scenes\"][0][\"id\"]\n",
    "        \n",
    "    elif any(word in start_response for word in [\"no\", \"change\"]):\n",
    "        new_story = ask_for_new_story(customer_name, chosen_story)\n",
    "\n",
    "\n",
    "\n",
    "    # intro = first scene in JSON\n",
    "    scene_id = story[\"scenes\"][0][\"id\"]\n",
    "\n",
    "\n",
    "    while True:\n",
    "        scene = get_scene(story, scene_id)\n",
    "\n",
    "        try:\n",
    "            text_to_say = generate_scene_text_llm(story, scene, emotion)\n",
    "        except Exception as e:\n",
    "            print(\"LLM error:\", e)\n",
    "            # fallback to old rule-based template\n",
    "            text_to_say = scene.get(\"description\", \"I cannot think of anything to say right now.\")\n",
    "\n",
    "        furhat.say(text=text_to_say, blocking=True)\n",
    "\n",
    "        # no options -> end\n",
    "        if not scene.get(\"options\"):\n",
    "            furhat.say(text=\"That was the end of this story.\", blocking=True)\n",
    "            break\n",
    "\n",
    "        # read options\n",
    "        furhat.say(text=\"What would you like to do next?\", blocking=True)\n",
    "        for idx, opt in enumerate(scene[\"options\"], start=1):\n",
    "            furhat.say(text=f\"Option {idx}: {opt['text']}\", blocking=True)\n",
    "\n",
    "        # listen for choice / meta-intents\n",
    "        answer = listen_text()\n",
    "\n",
    "        # global intents\n",
    "        if \"quit\" in answer or \"stop\" in answer:\n",
    "            furhat.say(text=\"Okay, I will stop the story here.\", blocking=True)\n",
    "            break\n",
    "\n",
    "        if \"change\" in answer or \"another\" in answer:\n",
    "            new_story = ask_for_new_story(customer_name, chosen_story)\n",
    "            story = STORIES[new_story]\n",
    "            continue\n",
    "\n",
    "        if \"repeat\" in answer:\n",
    "            # just repeat current scene\n",
    "            furhat.say(text=\"Let me repeat that part.\", blocking=True)\n",
    "            continue\n",
    "\n",
    "        # choose option\n",
    "        opt = choose_option_from_speech(scene, answer)\n",
    "        scene_id = opt[\"nextScene\"]\n",
    "        \n",
    "        # This should be done by webcam\n",
    "        furhat.say(text=\"If I looked at your face, would you say you feel happy, sad, angry, afraid, disgusted, surprised, or neutral?\", blocking=True)\n",
    "        emotionresponse = furhat.listen()\n",
    "\n",
    "        if emotionresponse and emotionresponse.message:\n",
    "            user_emotion = detect_emotion_from_text(emotionresponse.message)\n",
    "            furhat.say(text=f\"You answered, {user_emotion}\", blocking = True)\n",
    "            if emotionresponse not in EMOTIONS:\n",
    "                emotion = \"neutral\"\n",
    "            else:\n",
    "                emotion=user_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_story_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
